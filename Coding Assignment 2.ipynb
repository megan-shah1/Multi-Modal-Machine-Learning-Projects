{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9f53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PART-1--EXPLORATORY-DATA-STAGE------------------\n",
    "#import pandas library, regex, and mat plot lib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "#read in data from csv files\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750c6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display of Training Data: \n",
      "\n",
      "           Index  Sentiment                                               Text\n",
      "0              0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1              1          0  is upset that he can't update his Facebook by ...\n",
      "2              2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3              3          0    my whole body feels itchy and like its on fire \n",
      "4              4          0  @nationwideclass no, it's not behaving at all....\n",
      "...          ...        ...                                                ...\n",
      "1048570  1048570          1  Back home, thought I'd done for the week, but ...\n",
      "1048571  1048571          1           My GrandMa is making Dinenr with my Mum \n",
      "1048572  1048572          1  Mid-morning snack time... A bowl of cheese noo...\n",
      "1048573  1048573          1  @ShaDeLa same here  say it like from the Termi...\n",
      "1048574  1048574          1             @DestinyHope92 im great thaanks  wbuu?\n",
      "\n",
      "[1048575 rows x 3 columns]\n",
      "\n",
      "Display of Testing Data: \n",
      "\n",
      "     Index  Sentiment                                               Text\n",
      "0        0          1  @stellargirl I loooooooovvvvvveee my Kindle2. ...\n",
      "1        1          1  Reading my kindle2...  Love it... Lee childs i...\n",
      "2        2          1  Ok, first assesment of the #kindle2 ...it fuck...\n",
      "3        3          1  @kenburbary You'll love your Kindle2. I've had...\n",
      "4        4          1  @mikefish  Fair enough. But i have the Kindle2...\n",
      "..     ...        ...                                                ...\n",
      "354    492          1  After using LaTeX a lot, any other typeset mat...\n",
      "355    494          0  On that note, I hate Word. I hate Pages. I hat...\n",
      "356    495          1  Ahhh... back in a *real* text editing environm...\n",
      "357    496          0  Trouble in Iran, I see. Hmm. Iran. Iran so far...\n",
      "358    497          0  Reading the tweets coming out of Iran... The w...\n",
      "\n",
      "[359 rows x 3 columns]\n",
      "\n",
      "Size of Data: \n",
      "\n",
      "Training dataset size: (1048575, 3)\n",
      "Test dataset size: (359, 3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Train Data: \n",
      "Index        0\n",
      "Sentiment    0\n",
      "Text         0\n",
      "dtype: int64\n",
      "Missing Values in Test Data: \n",
      "Index        0\n",
      "Sentiment    0\n",
      "Text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display train and test data\n",
    "print(\"Display of Training Data: \")\n",
    "print()\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Display of Testing Data: \")\n",
    "print()\n",
    "print(test_data)\n",
    "print()\n",
    "\n",
    "# Print the size of training and test data\n",
    "print(\"Size of Data: \")\n",
    "print()\n",
    "print(\"Training dataset size:\", train_data.shape)\n",
    "print(\"Test dataset size:\", test_data.shape)\n",
    "\n",
    "# Analyze sentiment distribution of training data\n",
    "print()\n",
    "train_data['Sentiment'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Sentiment Distribution in Training Data\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Check training and testing data to see if missing values exist\n",
    "print()\n",
    "print(\"Missing Values in Train Data: \")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"Missing Values in Test Data: \")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Drop values that are null\n",
    "train_data.dropna(subset=['Text'], inplace=True)\n",
    "test_data.dropna(subset=['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86fda5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data after Text Preprocessing: \n",
      "           Index  Sentiment                                               Text\n",
      "0              0          0  switchfoot http twitpic com yzl awww that s a ...\n",
      "1              1          0  is upset that he can t update his facebook by ...\n",
      "2              2          0  kenichan i dived many times for the ball manag...\n",
      "3              3          0     my whole body feels itchy and like its on fire\n",
      "4              4          0  nationwideclass no it s not behaving at all i ...\n",
      "...          ...        ...                                                ...\n",
      "1048570  1048570          1  back home thought i d done for the week but ju...\n",
      "1048571  1048571          1            my grandma is making dinenr with my mum\n",
      "1048572  1048572          1  mid morning snack time a bowl of cheese noodle...\n",
      "1048573  1048573          1  shadela same here say it like from the termini...\n",
      "1048574  1048574          1                  destinyhope im great thaanks wbuu\n",
      "\n",
      "[1048575 rows x 3 columns]\n",
      "\n",
      "Test Data after Text Preprocessing: \n",
      "     Index  Sentiment                                               Text\n",
      "0        0          1  stellargirl i loooooooovvvvvveee my kindle not...\n",
      "1        1          1  reading my kindle love it lee childs is good read\n",
      "2        2          1  ok first assesment of the kindle it fucking rocks\n",
      "3        3          1  kenburbary you ll love your kindle i ve had mi...\n",
      "4        4          1  mikefish fair enough but i have the kindle and...\n",
      "..     ...        ...                                                ...\n",
      "354    492          1  after using latex a lot any other typeset math...\n",
      "355    494          0  on that note i hate word i hate pages i hate l...\n",
      "356    495          1  ahhh back in a real text editing environment i...\n",
      "357    496          0  trouble in iran i see hmm iran iran so far awa...\n",
      "358    497          0  reading the tweets coming out of iran the whol...\n",
      "\n",
      "[359 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---- PART-2--TEXT-PREPROCESSING------------------\n",
    "# Convert text column to all lower case in training and test data\n",
    "train_data['Text'] = train_data['Text'].str.lower()\n",
    "test_data['Text'] = test_data['Text'].str.lower()\n",
    "\n",
    "# Remove non-alphabetical or non-numerical characters\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "test_data['Text'] = test_data['Text'].apply(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "\n",
    "# Remove digital numbers\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "test_data['Text'] = test_data['Text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "# Remove extra whitespaces\n",
    "train_data['Text'] = train_data['Text'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "test_data['Text'] = test_data['Text'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "# Print test and training data after preprocessing\n",
    "print()\n",
    "print(\"Train Data after Text Preprocessing: \")\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Test Data after Text Preprocessing: \")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6102fe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag of Words Features on Training Data\n",
      "  (0, 382116)\t1\n",
      "  (0, 168820)\t1\n",
      "  (0, 409286)\t1\n",
      "  (0, 77535)\t1\n",
      "  (0, 445674)\t1\n",
      "  (0, 29779)\t1\n",
      "  (0, 390208)\t1\n",
      "  (0, 55159)\t1\n",
      "  (0, 443707)\t1\n",
      "  (0, 356007)\t1\n",
      "  (0, 150159)\t1\n",
      "  (0, 92346)\t1\n",
      "  (0, 61364)\t1\n",
      "  (0, 289395)\t1\n",
      "  (0, 395312)\t1\n",
      "  (0, 93075)\t1\n",
      "  (0, 399893)\t1\n",
      "  (0, 104522)\t1\n",
      "  (0, 181313)\t1\n",
      "  (1, 390208)\t1\n",
      "  (1, 181313)\t1\n",
      "  (1, 180551)\t1\n",
      "  (1, 415162)\t1\n",
      "  (1, 159664)\t1\n",
      "  (1, 59081)\t1\n",
      "  :\t:\n",
      "  (1048572, 266555)\t1\n",
      "  (1048572, 363370)\t1\n",
      "  (1048572, 67537)\t1\n",
      "  (1048572, 444925)\t1\n",
      "  (1048572, 48891)\t1\n",
      "  (1048572, 285089)\t1\n",
      "  (1048573, 181313)\t1\n",
      "  (1048573, 390562)\t1\n",
      "  (1048573, 228348)\t2\n",
      "  (1048573, 162210)\t1\n",
      "  (1048573, 201961)\t1\n",
      "  (1048573, 138432)\t1\n",
      "  (1048573, 344982)\t1\n",
      "  (1048573, 77712)\t1\n",
      "  (1048573, 341609)\t1\n",
      "  (1048573, 289441)\t1\n",
      "  (1048573, 433583)\t1\n",
      "  (1048573, 267527)\t1\n",
      "  (1048573, 351230)\t1\n",
      "  (1048573, 388882)\t1\n",
      "  (1048574, 175168)\t1\n",
      "  (1048574, 151599)\t1\n",
      "  (1048574, 98165)\t1\n",
      "  (1048574, 389862)\t1\n",
      "  (1048574, 425702)\t1\n",
      "\n",
      "Bag of Words Features on Testing Data\n",
      "  (0, 56006)\t1\n",
      "  (0, 80096)\t1\n",
      "  (0, 111225)\t1\n",
      "  (0, 127645)\t1\n",
      "  (0, 176414)\t1\n",
      "  (0, 180551)\t2\n",
      "  (0, 181627)\t1\n",
      "  (0, 212630)\t1\n",
      "  (0, 272808)\t1\n",
      "  (0, 285781)\t1\n",
      "  (0, 296697)\t1\n",
      "  (0, 331987)\t1\n",
      "  (0, 372664)\t1\n",
      "  (0, 390208)\t1\n",
      "  (0, 390562)\t2\n",
      "  (1, 69193)\t1\n",
      "  (1, 149278)\t1\n",
      "  (1, 180551)\t1\n",
      "  (1, 181313)\t1\n",
      "  (1, 212630)\t1\n",
      "  (1, 224733)\t1\n",
      "  (1, 235473)\t1\n",
      "  (1, 272808)\t1\n",
      "  (1, 324913)\t1\n",
      "  (1, 324948)\t1\n",
      "  :\t:\n",
      "  (356, 236840)\t1\n",
      "  (356, 325039)\t1\n",
      "  (356, 389494)\t1\n",
      "  (357, 29311)\t1\n",
      "  (357, 127729)\t1\n",
      "  (357, 165061)\t1\n",
      "  (357, 176414)\t1\n",
      "  (357, 180033)\t3\n",
      "  (357, 348575)\t1\n",
      "  (357, 364229)\t1\n",
      "  (357, 405828)\t1\n",
      "  (358, 17087)\t1\n",
      "  (358, 77810)\t1\n",
      "  (358, 176790)\t1\n",
      "  (358, 180033)\t1\n",
      "  (358, 180551)\t1\n",
      "  (358, 289395)\t1\n",
      "  (358, 295684)\t1\n",
      "  (358, 324948)\t1\n",
      "  (358, 340224)\t1\n",
      "  (358, 389037)\t1\n",
      "  (358, 390562)\t2\n",
      "  (358, 395107)\t1\n",
      "  (358, 408319)\t1\n",
      "  (358, 429461)\t1\n",
      "\n",
      "\n",
      "TFIDF Features on Training Data\n",
      "  (0, 181313)\t0.09144076696379616\n",
      "  (0, 104522)\t0.13729849249529727\n",
      "  (0, 399893)\t0.07217531652550858\n",
      "  (0, 93075)\t0.12927475303902983\n",
      "  (0, 395312)\t0.2783806721387473\n",
      "  (0, 289395)\t0.10589000885019872\n",
      "  (0, 61364)\t0.3623240992449239\n",
      "  (0, 92346)\t0.24450690459057878\n",
      "  (0, 150159)\t0.1395032915783918\n",
      "  (0, 356007)\t0.3009275176161622\n",
      "  (0, 443707)\t0.09991245447006641\n",
      "  (0, 55159)\t0.24856731554400063\n",
      "  (0, 390208)\t0.10932194983461185\n",
      "  (0, 29779)\t0.21495860435585318\n",
      "  (0, 445674)\t0.4510692965719627\n",
      "  (0, 77535)\t0.15200168100788747\n",
      "  (0, 409286)\t0.18284336496848183\n",
      "  (0, 168820)\t0.1410964669190291\n",
      "  (0, 382116)\t0.3888989987897275\n",
      "  (1, 43720)\t0.3007092182550968\n",
      "  (1, 13745)\t0.2342482674161129\n",
      "  (1, 400137)\t0.15818242125939222\n",
      "  (1, 346112)\t0.20222133792564695\n",
      "  (1, 329780)\t0.3379007247823705\n",
      "  (1, 24825)\t0.1899765835515452\n",
      "  :\t:\n",
      "  (1048572, 67537)\t0.34867563465397217\n",
      "  (1048572, 363370)\t0.41413597976529903\n",
      "  (1048572, 266555)\t0.2161740710910903\n",
      "  (1048572, 256658)\t0.38838093774397736\n",
      "  (1048572, 397891)\t0.1923801143103389\n",
      "  (1048572, 289395)\t0.14204784564550996\n",
      "  (1048573, 388882)\t0.505667862173437\n",
      "  (1048573, 351230)\t0.505667862173437\n",
      "  (1048573, 267527)\t0.25878275745954266\n",
      "  (1048573, 433583)\t0.2707549146691967\n",
      "  (1048573, 289441)\t0.1695667018557845\n",
      "  (1048573, 341609)\t0.21214905674334128\n",
      "  (1048573, 77712)\t0.25495226738202786\n",
      "  (1048573, 344982)\t0.20258020175612532\n",
      "  (1048573, 138432)\t0.15592858038945925\n",
      "  (1048573, 201961)\t0.12694784059424463\n",
      "  (1048573, 162210)\t0.16914595951403044\n",
      "  (1048573, 228348)\t0.28748763582207043\n",
      "  (1048573, 390562)\t0.08318356089559532\n",
      "  (1048573, 181313)\t0.09957571955203576\n",
      "  (1048574, 425702)\t0.5699048347761936\n",
      "  (1048574, 389862)\t0.5356119595731768\n",
      "  (1048574, 98165)\t0.5527583971746852\n",
      "  (1048574, 151599)\t0.21912643647135588\n",
      "  (1048574, 175168)\t0.1864673356197784\n",
      "\n",
      "TFIDF Features on Testing Data\n",
      "  (0, 390562)\t0.17371486334110428\n",
      "  (0, 390208)\t0.12430552671975623\n",
      "  (0, 372664)\t0.5280011015860364\n",
      "  (0, 331987)\t0.18737756900756927\n",
      "  (0, 296697)\t0.2540790547529589\n",
      "  (0, 285781)\t0.1320134341545259\n",
      "  (0, 272808)\t0.09834568868316215\n",
      "  (0, 212630)\t0.3829824053305217\n",
      "  (0, 181627)\t0.16976738585458254\n",
      "  (0, 180551)\t0.21884662704155533\n",
      "  (0, 176414)\t0.11353200463612083\n",
      "  (0, 127645)\t0.30110846995365886\n",
      "  (0, 111225)\t0.3955201797762416\n",
      "  (0, 80096)\t0.22281372982725345\n",
      "  (0, 56006)\t0.12566561371213858\n",
      "  (1, 324948)\t0.3074996101974654\n",
      "  (1, 324913)\t0.28285599775650994\n",
      "  (1, 272808)\t0.1183241628417232\n",
      "  (1, 235473)\t0.20469423581464052\n",
      "  (1, 224733)\t0.41003085252951404\n",
      "  (1, 212630)\t0.4607835188366736\n",
      "  (1, 181313)\t0.12509531462150777\n",
      "  (1, 180551)\t0.13165215619594484\n",
      "  (1, 149278)\t0.18351046036042196\n",
      "  (1, 69193)\t0.5678311089426724\n",
      "  :\t:\n",
      "  (356, 113474)\t0.38003502203196265\n",
      "  (356, 31487)\t0.1861018256217491\n",
      "  (356, 8208)\t0.32123337788445677\n",
      "  (357, 405828)\t0.263656413473671\n",
      "  (357, 364229)\t0.11364493963997613\n",
      "  (357, 348575)\t0.15739672382345832\n",
      "  (357, 180033)\t0.8586505288877316\n",
      "  (357, 176414)\t0.10352491636602175\n",
      "  (357, 165061)\t0.24783715411336477\n",
      "  (357, 127729)\t0.21451931061495333\n",
      "  (357, 29311)\t0.19327820881974503\n",
      "  (358, 429461)\t0.27773063414705973\n",
      "  (358, 408319)\t0.28120304547997804\n",
      "  (358, 395107)\t0.24146207857721175\n",
      "  (358, 390562)\t0.19881843800613966\n",
      "  (358, 389037)\t0.4454121323659395\n",
      "  (358, 340224)\t0.19786703449966717\n",
      "  (358, 324948)\t0.2925136476217023\n",
      "  (358, 295684)\t0.16920297208373863\n",
      "  (358, 289395)\t0.1378027016785007\n",
      "  (358, 180551)\t0.1252361016048382\n",
      "  (358, 180033)\t0.35924297434001445\n",
      "  (358, 176790)\t0.3875948071770394\n",
      "  (358, 77810)\t0.25764096497981515\n",
      "  (358, 17087)\t0.11782547621618525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- PART-3--LINGUISTIC-FEATURE-EXTRACTION-----------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Count vector is created to extract bag-of-words features\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# Find and extract Bag of Words features\n",
    "bag_train = count_vect.fit_transform(train_data['Text'])\n",
    "bag_test = count_vect.transform(test_data['Text'])\n",
    "\n",
    "# Print Bag of Word Features\n",
    "print()\n",
    "print(\"Bag of Words Features on Training Data\")\n",
    "print(bag_train)\n",
    "print()\n",
    "print(\"Bag of Words Features on Testing Data\")\n",
    "print(bag_test)\n",
    "print()\n",
    "\n",
    "# TFIDF vector is created to extract TF-IDF features\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# Find and extract TFIDF features\n",
    "tfidf_train = tfidf_vect.fit_transform(train_data['Text'])\n",
    "tfidf_test = tfidf_vect.transform(test_data['Text'])\n",
    "\n",
    "# Print TFIDF Features\n",
    "print()\n",
    "print(\"TFIDF Features on Training Data\")\n",
    "print(tfidf_train)\n",
    "print()\n",
    "print(\"TFIDF Features on Testing Data\")\n",
    "print(tfidf_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ff79ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/meganshah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 Word2Vec Features in Training Data: \n",
      "[('week', 0.997859001159668), ('her', 0.997855544090271), ('hate', 0.9978485703468323), ('not', 0.9978304505348206), ('only', 0.9978172779083252), ('through', 0.9978129267692566), ('u', 0.9978020191192627), ('and', 0.997799813747406), ('though', 0.9977937936782837), ('im', 0.9977924823760986)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features using Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# load data\n",
    "word2vec_train = train_data.head(5000)\n",
    "sentences = word2vec_train['Text'].apply(nltk.word_tokenize).tolist()\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word_vectors = model.wv\n",
    "vector = word_vectors['test']\n",
    "train_word2vec = word_vectors.most_similar('test', topn=10)\n",
    "\n",
    "print()\n",
    "print(\"First 10 Word2Vec Features in Training Data: \")\n",
    "print(train_word2vec[:10])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b073402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Model Performance with Logistic Regression:\n",
      "Accuracy: 0.7465181058495822\n",
      "Precision: 0.9026548672566371\n",
      "Recall: 0.5604395604395604\n",
      "F1-Score: 0.6915254237288136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meganshah/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# ---- PART-4--BUILDING-SENTIMENT-MODEL-----------------\n",
    "# Import statements for machine learning algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Set y_train and y_test values to sentiment column of database\n",
    "y_train = train_data['Sentiment'].values\n",
    "y_test = test_data['Sentiment'].values\n",
    "\n",
    "# Train Logistic Regression Model on Bag of Words Features\n",
    "lr_bag = LogisticRegression(random_state=42)\n",
    "lr_bag.fit(bag_train, y_train)\n",
    "\n",
    "# Predict test data\n",
    "lr_y_pred_bag = lr_bag.predict(bag_test)\n",
    "\n",
    "# Calculate analytics of model\n",
    "lr_accuracy_bag = accuracy_score(y_test, lr_y_pred_bag)\n",
    "lr_precision_bag = precision_score(y_test, lr_y_pred_bag, average='binary', pos_label=1)\n",
    "lr_recall_bag = recall_score(y_test, lr_y_pred_bag, average='binary', pos_label=1)\n",
    "lr_f1_bag = f1_score(y_test, lr_y_pred_bag, average='binary', pos_label=1)\n",
    "\n",
    "# Print LR model performance\n",
    "print('Bag-of-Words Model Performance with Logistic Regression:')\n",
    "print('Accuracy:', lr_accuracy_bag)\n",
    "print('Precision:', lr_precision_bag)\n",
    "print('Recall:', lr_recall_bag)\n",
    "print('F1-Score:', lr_f1_bag)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9399f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag-of-Words Model Performance with Naive Bayes:\n",
      "Accuracy: 0.6852367688022284\n",
      "Precision: 0.8415841584158416\n",
      "Recall: 0.46703296703296704\n",
      "F1-Score: 0.6007067137809187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes Model on Bag of Words Features\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_bag = MultinomialNB()\n",
    "nb_bag.fit(bag_train, y_train)\n",
    "\n",
    "# Predict Test Data\n",
    "nb_y_pred_bag = nb_bag.predict(bag_test)\n",
    "\n",
    "# Calculate analytics of model\n",
    "nb_accuracy_bag = accuracy_score(y_test, nb_y_pred_bag)\n",
    "nb_precision_bag = precision_score(y_test, nb_y_pred_bag, average='binary', pos_label=1)\n",
    "nb_recall_bag = recall_score(y_test, nb_y_pred_bag, average='binary', pos_label=1)\n",
    "nb_f1_bag = f1_score(y_test, nb_y_pred_bag, average='binary', pos_label=1)\n",
    "\n",
    "# Print Naive Bayes model performance\n",
    "print()\n",
    "print('Bag-of-Words Model Performance with Naive Bayes:')\n",
    "print('Accuracy:', nb_accuracy_bag)\n",
    "print('Precision:', nb_precision_bag)\n",
    "print('Recall:', nb_recall_bag)\n",
    "print('F1-Score:', nb_f1_bag)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Model on Bag of Words Features\n",
    "rf_bag = RandomForestClassifier()\n",
    "rf_bag.fit(bag_train, y_train)\n",
    "\n",
    "# Predict Test Data\n",
    "rf_y_pred_bag = rf_bag.predict(bag_test)\n",
    "\n",
    "# Calculate analytics of model\n",
    "rf_accuracy_bag = accuracy_score(y_test, rf_y_pred_bag)\n",
    "rf_precision_bag = precision_score(y_test, rf_y_pred_bag, average='binary', pos_label=1)\n",
    "rf_recall_bag = recall_score(y_test, rf_y_pred_bag, average='binary', pos_label=1)\n",
    "rf_f1_bag = f1_score(y_test, rf_y_pred_bag, average='binary', pos_label=1)\n",
    "\n",
    "# Print Random Forest model performance\n",
    "print()\n",
    "print('Bag-of-Words Model Performance with Random Forest:')\n",
    "print('Accuracy:', rf_accuracy_bag)\n",
    "print('Precision:', rf_precision_bag)\n",
    "print('Recall:', rf_recall_bag)\n",
    "print('F1-Score:', rf_f1_bag)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM Model on Bag of Words Features\n",
    "svc_bag = SVC(kernel='linear')\n",
    "svc_bag.fit(bag_train, y_train)\n",
    "\n",
    "# Predict Test Data\n",
    "svc_y_pred_bag = svc_bag.predict(bag_test)\n",
    "\n",
    "# Calculate analytics of model\n",
    "svc_accuracy_bag = accuracy_score(y_test, svc_y_pred_bag)\n",
    "svc_precision_bag = precision_score(y_test, svc_y_pred_bag, average='binary', pos_label=1)\n",
    "svc_recall_bag = recall_score(y_test, svc_y_pred_bag, average='binary', pos_label=1)\n",
    "svc_f1_bag = f1_score(y_test, svc_y_pred_bag, average='binary', pos_label=1)\n",
    "\n",
    "# Print SVC model performance\n",
    "print()\n",
    "print('Bag-of-Words Model Performance with SVC:')\n",
    "print('Accuracy:', svc_accuracy_bag)\n",
    "print('Precision:', svc_precision_bag)\n",
    "print('Recall:', svc_recall_bag)\n",
    "print('F1-Score:', svc_f1_bag)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model on TFIDF Features\n",
    "lr_tfidf = LogisticRegression(random_state=42)\n",
    "lr_tfidf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predict test data\n",
    "lr_y_pred_tfidf = lr_tfidf.predict(tfidf_test)\n",
    "\n",
    "# Calculate analytics of model\n",
    "lr_accuracy_tfidf = accuracy_score(y_test, lr_y_pred_tfidf)\n",
    "lr_precision_tfidf = precision_score(y_test, lr_y_pred_tfidf, average='binary', pos_label=1)\n",
    "lr_recall_tfidf = recall_score(y_test, lr_y_pred_tfidf, average='binary', pos_label=1)\n",
    "lr_f1_tfidf = f1_score(y_test, lr_y_pred_tfidf, average='binary', pos_label=1)\n",
    "\n",
    "# Print LR model performance\n",
    "print('TFIDF Model Performance with Logistic Regression:')\n",
    "print('Accuracy:', lr_accuracy_tfidf)\n",
    "print('Precision:', lr_precision_tfidf)\n",
    "print('Recall:', lr_recall_tfidf)\n",
    "print('F1-Score:', lr_f1_tfidf)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673706a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes Model on Bag of Words Features\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predict Test Data\n",
    "nb_y_pred_tfidf = nb_tfidf.predict(tfidf_test)\n",
    "\n",
    "# Calculate analytics of model\n",
    "nb_accuracy_tfidf = accuracy_score(y_test, nb_y_pred_tfidf)\n",
    "nb_precision_tfidf = precision_score(y_test, nb_y_pred_tfidf, average='binary', pos_label=1)\n",
    "nb_recall_tfidf = recall_score(y_test, nb_y_pred_tfidf, average='binary', pos_label=1)\n",
    "nb_f1_tfidf = f1_score(y_test, nb_y_pred_tfidf, average='binary', pos_label=1)\n",
    "\n",
    "# Print Naive Bayes model performance\n",
    "print()\n",
    "print('TFIDF Model Performance with Naive Bayes:')\n",
    "print('Accuracy:', nb_accuracy_tfidf)\n",
    "print('Precision:', nb_precision_tfidf)\n",
    "print('Recall:', nb_recall_tfidf)\n",
    "print('F1-Score:', nb_f1_tfidf)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedafcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM Model on TFIDF Features\n",
    "svc_tfidf = SVC(kernel='linear')\n",
    "svc_tfidf.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predict Test Data\n",
    "svc_y_pred_tfidf = svc_bag.predict(tfidf_test)\n",
    "\n",
    "# Calculate analytics of model\n",
    "svc_accuracy_tfidf = accuracy_score(y_test, svc_y_pred_tfidf)\n",
    "svc_precision_tfidf = precision_score(y_test, svc_y_pred_tfidf, average='binary', pos_label=1)\n",
    "svc_recall_tfidf = recall_score(y_test, svc_y_pred_tfidf, average='binary', pos_label=1)\n",
    "svc_f1_tfidf = f1_score(y_test, svc_y_pred_tfidf, average='binary', pos_label=1)\n",
    "\n",
    "# Print SVC model performance\n",
    "print()\n",
    "print('TFIDF Model Performance with SVC:')\n",
    "print('Accuracy:', svc_accuracy_tfidf)\n",
    "print('Precision:', svc_precision_tfidf)\n",
    "print('Recall:', svc_recall_tfidf)\n",
    "print('F1-Score:', svc_f1_tfidf)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab2b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
